version: '3.7'

services:
  # 小红书爬虫服务
  xhs-crawler:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    container_name: xhs-crawler
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      # 应用配置
      NODE_ENV: production
      PORT: 3000
      # 数据库配置
      DATABASE_PATH: /app/data/accounts.db
      # Puppeteer配置
      PUPPETEER_SKIP_CHROMIUM_DOWNLOAD: "true"
      PUPPETEER_EXECUTABLE_PATH: /usr/bin/chromium-browser
      # 浏览器连接池配置
      BROWSER_POOL_MAX_INSTANCES: 5
      BROWSER_POOL_MIN_INSTANCES: 3
      BROWSER_POOL_IDLE_TIMEOUT_MINUTES: 30
      BROWSER_POOL_HEALTH_CHECK_INTERVAL_SECONDS: 60
      BROWSER_POOL_GET_BROWSER_TIMEOUT_SECONDS: 30
    volumes:
      # 持久化数据库
      - ./data:/app/data
      # 持久化日志
      - ./logs:/app/logs
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3000/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 10s
    networks:
      - xhs-network

networks:
  xhs-network:
    driver: bridge
